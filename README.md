# ğŸ§  Gen-Z Mental Wellness â€” ML Pipeline Dashboard

> A dual-target machine learning pipeline comparing **Regression** and **Classification** on Gen-Z mental wellness data, deployed as an interactive Streamlit web app.

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://your-username-genz-mental-wellness-app.streamlit.app)

---

## ğŸ“Œ Project Overview

This project builds a complete end-to-end ML pipeline on a Gen-Z mental wellness dataset. It simultaneously solves **two different ML problems** using the same set of features:

| Target Variable | Type | Problem |
|----------------|------|---------|
| `Wellbeing_Index` | Continuous score (1â€“10) | Regression |
| `Burnout_Risk` | Low / Medium / High | Classification |

The pipeline follows 8 steps from the whiteboard plan:

```
Raw CSV Data
      â†“
Step 0 â€” Imports & Setup
      â†“
Step 1 â€” Load & Explore (EDA)
      â†“
Step 2 â€” Feature Engineering
         â€¢ Correlation Heatmap â†’ Redundant Feature Detection
         â€¢ PCA â€” Principal Component Analysis
      â†“
Step 3 â€” Preprocessing (Encode, Split)
      â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   ğŸ”´ CLASSIFICATION      â”‚        â”‚   ğŸ”µ REGRESSION           â”‚
      â”‚   Target: Burnout_Risk   â”‚        â”‚   Target: Wellbeing_Index â”‚
      â”‚                          â”‚        â”‚                           â”‚
      â”‚  Step 1: SMOTE Balancing â”‚        â”‚  Step 1: Train/Test Split â”‚
      â”‚  Step 2: Pie Charts      â”‚        â”‚  Step 2: StandardScaler   â”‚
      â”‚  Step 3: StandardScaler  â”‚        â”‚  Step 3: 6 Regressors +   â”‚
      â”‚  Step 4: 6 Classifiers + â”‚        â”‚          10-Fold CV       â”‚
      â”‚          10-Fold CV      â”‚        â”‚  Step 4: MAE / RMSE / RÂ²  â”‚
      â”‚  Step 5: Acc/Prec/Rec/F1 â”‚        â”‚  Step 5: GridSearchCV     â”‚
      â”‚  Step 6: GridSearchCV    â”‚        â”‚          (on-demand btn)  â”‚
      â”‚          (on-demand btn) â”‚        â”‚  Step 6: Feature Importanceâ”‚
      â”‚  Step 7: Feature Imp     â”‚        â”‚  Step 7: Permutation XAI  â”‚
      â”‚  Step 8: Permutation XAI â”‚        â”‚                           â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
              ğŸ”® Live Prediction (both targets)
```

---

## ğŸ“‚ Project Structure

```
genz-mental-wellness-app/
â”œâ”€â”€ app.py                                      # Streamlit web app (main file)
â”œâ”€â”€ requirements.txt                            # Python dependencies
â”œâ”€â”€ README.md                                   # This file
â””â”€â”€ genz_mental_wellness_synthetic_dataset.csv  # Dataset (10,000 rows)
```

---

## ğŸ“Š Dataset

**File:** `genz_mental_wellness_synthetic_dataset.csv`
**Rows:** 10,000 synthetic samples Â· **Features:** 20 inputs + 2 targets

### Input Features

| Feature | Type | Description |
|---------|------|-------------|
| `Age` | Numeric | Age of respondent (18â€“25) |
| `Gender` | Categorical | Male / Female |
| `Country` | Categorical | Country of residence |
| `Student_Working_Status` | Categorical | Student or Working |
| `Daily_Social_Media_Hours` | Numeric | Hours on social media per day |
| `Screen_Time_Hours` | Numeric | Total daily screen time |
| `Night_Scrolling_Frequency` | Numeric | Frequency of night scrolling (0â€“7) |
| `Online_Gaming_Hours` | Numeric | Daily hours spent gaming |
| `Content_Type_Preference` | Categorical | News / Gaming / Entertainment / Educational |
| `Exercise_Frequency_per_Week` | Numeric | Days per week exercising |
| `Daily_Sleep_Hours` | Numeric | Average sleep hours per night |
| `Caffeine_Intake_Cups` | Numeric | Daily caffeine cups |
| `Study_Work_Hours_per_Day` | Numeric | Hours studying or working per day |
| `Overthinking_Score` | Numeric | Self-reported overthinking (1â€“10) |
| `Anxiety_Score` | Numeric | Anxiety level (1â€“10) |
| `Mood_Stability_Score` | Numeric | Mood stability (1â€“10) |
| `Social_Comparison_Index` | Numeric | Social comparison tendency (1â€“10) |
| `Sleep_Quality_Score` | Numeric | Sleep quality rating (1â€“10) |
| `Motivation_Level` | Numeric | Motivation score (1â€“10) |
| `Emotional_Fatigue_Score` | Numeric | Emotional fatigue level (1â€“10) |

### Target Variables

| Variable | Type | Values | Task |
|----------|------|--------|------|
| `Wellbeing_Index` | Continuous | 1.0 â€“ 10.0 | Regression |
| `Burnout_Risk` | Categorical | Low / Medium / High | Classification |

---

## ğŸ–¥ï¸ App Tabs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ§  Gen-Z Mental Wellness â€” ML Pipeline Dashboard               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SIDEBAR         â”‚                                              â”‚
â”‚                  â”‚  ğŸ“Š EDA & Feature Engineering                â”‚
â”‚  ğŸ“‚ Upload CSV   â”‚     â€¢ Dataset overview metrics               â”‚
â”‚                  â”‚     â€¢ Raw data preview                       â”‚
â”‚  Test Size       â”‚     â€¢ Descriptive statistics                 â”‚
â”‚  [slider]        â”‚     â€¢ Burnout_Risk pie chart                 â”‚
â”‚                  â”‚     â€¢ Wellbeing_Index histogram              â”‚
â”‚  CV Folds        â”‚     â€¢ Correlation heatmap                    â”‚
â”‚  [slider]        â”‚     â€¢ PCA scree + cumulative variance        â”‚
â”‚                  â”‚                                              â”‚
â”‚  Classifiers:    â”‚  ğŸ”´ Classification (Burnout_Risk)            â”‚
â”‚  âœ… Log Reg      â”‚     â€¢ SMOTE pie charts before/after          â”‚
â”‚  âœ… Dec Tree     â”‚     â€¢ 6 models metrics table (highlighted)   â”‚
â”‚  âœ… Rand Forest  â”‚     â€¢ CV details expandable                  â”‚
â”‚  âœ… Grad Boost   â”‚     â€¢ Metrics bar chart comparison           â”‚
â”‚  âœ… SVM          â”‚     â€¢ ROC-AUC table                          â”‚
â”‚  âœ… KNN          â”‚     â€¢ Confusion matrix (best model)          â”‚
â”‚                  â”‚     â€¢ ğŸ” GridSearchCV button (on-demand)     â”‚
â”‚  Regressors:     â”‚                                              â”‚
â”‚  âœ… Linear Reg   â”‚  ğŸ”µ Regression (Wellbeing_Index)             â”‚
â”‚  âœ… Ridge        â”‚     â€¢ 6 models metrics table (highlighted)   â”‚
â”‚  âœ… Lasso        â”‚     â€¢ CV details expandable                  â”‚
â”‚  âœ… Dec Tree     â”‚     â€¢ MAE / RMSE / RÂ² bar charts             â”‚
â”‚  âœ… Rand Forest  â”‚     â€¢ Actual vs Predicted scatter plot       â”‚
â”‚  âœ… Grad Boost   â”‚     â€¢ ğŸ” GridSearchCV button (on-demand)     â”‚
â”‚                  â”‚                                              â”‚
â”‚  â–¶ Run Pipeline  â”‚  ğŸ§  Explainable AI                           â”‚
â”‚                  â”‚     â€¢ Feature importance (Classification)    â”‚
â”‚                  â”‚     â€¢ Feature importance (Regression)        â”‚
â”‚                  â”‚     â€¢ Permutation importance (Classification)â”‚
â”‚                  â”‚     â€¢ Permutation importance (Regression)    â”‚
â”‚                  â”‚     â€¢ Top 10 contributions tables            â”‚
â”‚                  â”‚                                              â”‚
â”‚                  â”‚  ğŸ”® Predict                                  â”‚
â”‚                  â”‚     â€¢ 20 input sliders + dropdowns           â”‚
â”‚                  â”‚     â€¢ Burnout Risk prediction + icon         â”‚
â”‚                  â”‚     â€¢ Wellbeing Index prediction             â”‚
â”‚                  â”‚     â€¢ Class probability bar chart            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Pipeline â€” Step by Step

### Step 1 â€” Data Loading & EDA
- Load CSV into pandas DataFrame
- Check shape, dtypes, missing values
- View class distribution of `Burnout_Risk` and distribution of `Wellbeing_Index`

---

### Step 2 â€” Feature Engineering

**Correlation Heatmap:**
- Encode all categorical columns to numbers using `LabelEncoder`
- Compute Pearson correlation between every feature pair (values between -1 and +1)
- Visualize as a lower-triangle heatmap using seaborn
- Flag feature pairs with |r| > 0.85 as potentially redundant

**PCA â€” Principal Component Analysis:**
- Standardize all numeric features to mean=0, std=1
- Fit PCA and compute explained variance per component
- Plot Scree Plot (variance per component) and Cumulative Variance curve
- Find minimum components needed to explain â‰¥95% of total variance

---

### Step 3 â€” Preprocessing

| Step | What happens |
|------|-------------|
| **One-Hot Encoding** | `pd.get_dummies()` converts Gender, Country etc. to binary columns |
| **drop_first=True** | Drops one dummy column per feature to avoid multicollinearity |
| **LabelEncoder** | Converts Burnout_Risk (High/Low/Medium) â†’ integers (0/1/2) |
| **Train/Test Split** | 80% train, 20% test Â· `stratify=y` for classification |
| **random_state=42** | Fixes randomness for reproducible results |

---

## ğŸ”´ Part A â€” Classification (Burnout_Risk)

### Step 1 â€” SMOTE
The dataset has severe class imbalance. SMOTE fixes it:

```
Before SMOTE:  Low â‰ˆ 0.6%   Medium â‰ˆ 72%   High â‰ˆ 7%
After SMOTE:   Low = 33.3%  Medium = 33.3%  High = 33.3%
```

**How SMOTE works:**
1. Pick a minority sample
2. Find its K nearest neighbors (also minority class)
3. Synthetically create a new point between them
4. Repeat until all classes are equal size

âš ï¸ Applied **only to training data** â€” never test data.

---

### Step 2 â€” Pie Charts (Before & After SMOTE)
Side-by-side pie charts showing class imbalance before SMOTE and perfect balance after.

---

### Step 3 â€” StandardScaler
```
z = (x âˆ’ mean) / std
```
- `fit_transform` on training data â€” learns mean & std from training only
- `transform` on test data â€” applies same values (prevents data leakage)

---

### Step 4 â€” Six Classifiers with 10-Fold CV

| Model | Core Idea |
|-------|-----------|
| **Logistic Regression** | Sigmoid on linear combination of features â†’ probability per class |
| **Decision Tree** | Recursive yes/no splits on feature thresholds |
| **Random Forest** | Hundreds of trees on random subsets â†’ majority vote |
| **Gradient Boosting** | Sequential trees, each correcting prior errors |
| **SVM** | Maximum-margin hyperplane separating classes |
| **KNN** | Majority vote among K nearest training neighbors |

**10-Fold Cross-Validation (StratifiedKFold):**
```
[F1][F2][F3][F4][F5][F6][F7][F8][F9][F10]
Round 1:  Train F2â€“F10 â†’ Test F1
Round 2:  Train F1,F3â€“F10 â†’ Test F2
...
Round 10: Train F1â€“F9 â†’ Test F10
Result:   mean Â± std across 10 scores
```

---

### Step 5 â€” Evaluation Metrics

| Metric | Formula | Meaning |
|--------|---------|---------|
| **Accuracy** | Correct / Total | Overall % correct |
| **Precision** | TP / (TP+FP) | Of predicted positives, how many were right? |
| **Recall** | TP / (TP+FN) | Of actual positives, how many did we catch? |
| **F1-Score** | 2Â·(PÂ·R)/(P+R) | Harmonic mean of Precision & Recall |
| **ROC-AUC** | Area under ROC | Separation quality across all thresholds (OvR) |

`average='weighted'` â€” per-class metric weighted by class size.

**Confusion Matrix:** 3Ã—3 grid â€” rows = actual, cols = predicted, diagonal = correct.

---

### Step 6 â€” GridSearchCV (On-Demand Button)

Automatically tunes the best-performing classifier:

```
Example â€” Random Forest:
  n_estimators:     [100, 200]       â†’ 2 options
  max_depth:        [None, 10, 20]   â†’ 3 options
  min_samples_split:[2, 5]           â†’ 2 options
  Total:  2 Ã— 3 Ã— 2 = 12 combinations Ã— 10 folds = 120 fits
```

- Scoring: `f1_weighted`
- Shows: best params, CV F1, test F1 delta vs default, before/after chart

---

### Step 7 â€” Feature Importance (Random Forest)
Tracks how much each feature reduces Gini impurity across all trees.
Higher = more useful for predicting Burnout_Risk.

---

### Step 8 â€” Explainable AI (Permutation Importance)
Works for **any model** â€” not just trees:
1. Compute baseline F1 on test data
2. Shuffle one feature column randomly
3. Measure F1 drop â†’ large drop = important feature
4. Repeat 20 times and average for stability

---

## ğŸ”µ Part B â€” Regression (Wellbeing_Index)

### Key Differences from Classification
- No SMOTE â€” continuous target cannot be "balanced"
- No `stratify` in train/test split
- Uses `KFold` instead of `StratifiedKFold`

### Six Regressors

| Model | Core Idea |
|-------|-----------|
| **Linear Regression** | Minimize sum of squared errors â€” fits a hyperplane |
| **Ridge** | Linear + L2 penalty â€” shrinks large coefficients |
| **Lasso** | Linear + L1 penalty â€” zeros out unimportant coefficients |
| **Decision Tree** | Predicts mean value of samples in each leaf node |
| **Random Forest** | Averages predictions from many decision trees |
| **Gradient Boosting** | Sequential trees fitting residual errors |

### Regression Metrics

| Metric | Formula | Meaning |
|--------|---------|---------|
| **MAE** | mean(\|actual âˆ’ pred\|) | Average absolute error â€” easy to interpret |
| **RMSE** | âˆšmean((actual âˆ’ pred)Â²) | Penalizes large errors more than MAE |
| **RÂ²** | 1 âˆ’ SS_res/SS_tot | % of variance explained (1.0 = perfect) |

### GridSearchCV (On-Demand Button)
Same pattern as classification â€” tunes best regressor:
- Scoring: `r2`
- Shows: best params, test RÂ² delta, before/after chart for MAE/RMSE/RÂ²
- Note: Linear Regression has no hyperparameters (handled gracefully)

---

## ğŸ§  Explainable AI Tab

| Chart | Model Used | What it measures |
|-------|-----------|-----------------|
| Feature Importance â€” Classification | Random Forest | Gini impurity reduction |
| Feature Importance â€” Regression | Random Forest | Gini impurity reduction |
| Permutation Importance â€” Classification | Best classifier | F1 drop on test data |
| Permutation Importance â€” Regression | Best regressor | RÂ² drop on test data |

Adjustable "Top N features" slider (5â€“20) for all charts.

---

## ğŸ”® Predict Tab

Input sliders and dropdowns for all 20 features â†’ click **Predict** â†’ outputs:

| Output | Description |
|--------|-------------|
| **Burnout Risk** | ğŸ”´ High / ğŸŸ¡ Medium / ğŸŸ¢ Low with color icon |
| **Wellbeing Index** | Predicted continuous score (e.g., 4.83 / 10) |
| **Probability Chart** | Horizontal bar chart showing confidence per class |

Uses the best-performing model from the pipeline run.

---

## âš™ï¸ Sidebar Controls

| Control | Description |
|---------|-------------|
| **Upload CSV** | Replace default dataset with your own |
| **Test Size** | Fraction for test split (0.10 â€“ 0.40, default 0.20) |
| **CV Folds** | Number of cross-validation folds (3â€“15, default 10) |
| **Classifiers** | Toggle any of the 6 classifiers on/off |
| **Regressors** | Toggle any of the 6 regressors on/off |

---

## âš™ï¸ Installation & Running Locally

```bash
# 1. Clone the repository
git clone https://github.com/YOUR_USERNAME/genz-mental-wellness-app.git
cd genz-mental-wellness-app

# 2. (Optional) Create a virtual environment
python -m venv venv
source venv/bin/activate        # Mac/Linux
venv\Scripts\activate           # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the app
streamlit run app.py
```

App opens automatically at: **http://localhost:8501**

---

## â˜ï¸ Deployment â€” Streamlit Community Cloud

1. Push all 4 files to a **public** GitHub repository
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Sign in with GitHub â†’ click **New app**
4. Select your repo, set branch to `main`, main file to `app.py`
5. Click **Deploy** â€” ready in ~3 minutes

**Live URL format:**
```
https://YOUR_USERNAME-genz-mental-wellness-app.streamlit.app
```

**Auto-redeploy:** Push any change to GitHub â†’ Streamlit redeploys automatically within 1â€“2 minutes.

---

## ğŸ“¦ Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| `streamlit` | â‰¥1.32.0 | Web app framework |
| `numpy` | â‰¥1.26.0 | Numerical computations |
| `pandas` | â‰¥2.0.0 | Data manipulation |
| `matplotlib` | â‰¥3.7.0 | Base plotting library |
| `seaborn` | â‰¥0.13.0 | Statistical visualizations |
| `scikit-learn` | â‰¥1.3.0 | ML models, metrics, preprocessing |
| `imbalanced-learn` | â‰¥0.11.0 | SMOTE for class balancing |

---

## ğŸ”‘ Key Concepts Quick Reference

| Concept | What it does |
|---------|-------------|
| **SMOTE** | Generates synthetic minority samples to fix class imbalance |
| **StandardScaler** | Rescales features to mean=0, std=1 |
| **Train/Test Split** | Simulates unseen real-world data for evaluation |
| **StratifiedKFold** | CV that maintains class ratio in each fold |
| **KFold** | Standard CV for regression (no classes to stratify) |
| **GridSearchCV** | Exhaustive search over hyperparameter combinations |
| **Accuracy** | % of all predictions that were correct |
| **F1-Score** | Best metric for imbalanced classification |
| **ROC-AUC** | Class separation quality across all thresholds |
| **Confusion Matrix** | Breakdown of correct and incorrect predictions per class |
| **MAE** | Average absolute error â€” easy to interpret |
| **RMSE** | Root mean squared error â€” penalizes large errors |
| **RÂ²** | % of variance in target explained by the model |
| **Feature Importance** | Tree-based measure of each feature's predictive contribution |
| **Permutation Importance** | Model-agnostic XAI â€” measures F1/RÂ² drop when feature is shuffled |
| **PCA** | Reduces dimensions while preserving maximum variance |
| **Correlation Heatmap** | Identifies redundant or multicollinear features |
| **Data Leakage** | When test data information influences training â€” prevented by fit/transform split |

---

## ğŸ‘¤ Author

Built as part of an Advanced Deep Learning project comparing classification and regression approaches on Gen-Z mental wellness data.
